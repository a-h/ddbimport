service: ddbimport

frameworkVersion: ">=1.28.0"

provider:
  name: aws
  memorySize: 2048 # optional, in MB, default is 1024
  timeout: 900 # optional, in seconds, default is 6
  versionFunctions: false # optional, default is true
  runtime: go1.x
  stage: dev
  region: eu-west-2
  iamRoleStatements:
    - Effect: Allow
      Action:
        - dynamodb:BatchWriteItem
      Resource: "*"
    - Effect: "Allow"
      Action:
        - "s3:ListBucket"
      Resource: "*"
    - Effect: "Allow"
      Action:
        - "s3:GetObject"
      Resource: "*"

stepFunctions:
  stateMachines:
    ddbimport:
      name: ddbimport
      definition:
        Comment: "Imports data into DynamoDB in parallel."
        StartAt: preflight
        States:
          preflight:
            Type: Task
            Resource:
              Fn::GetAtt: [preflight, Arn]
            Next: continue
          continue:
            Type: Choice
            Choices:
              - Variable: "$.prefl.cnt"
                BooleanEquals: false
                Next: process
            Default: preflight
          process:
            Type: Map
            InputPath: "$"
            ItemsPath: "$.batches"
            MaxConcurrency: 50
            Parameters:
              "src.$": "$.src"
              "cnf.$": "$.cnf"
              "tgt.$": "$.tgt"
              "cols.$": "$.prefl.cols"
              "range.$": "$$.Map.Item.Value"
            Iterator:
              StartAt: import
              States:
                import:
                  Type: Task
                  Resource:
                    Fn::GetAtt: [import, Arn]
                  End: true
            End: true

  validate: true # enable pre-deployment definition validation (disabled by default)

package:
  exclude:
    - ./**
  include:
    - ./bin/**

functions:
  preflight:
    handler: bin/preflight
  import:
    handler: bin/import

plugins:
  - serverless-step-functions
